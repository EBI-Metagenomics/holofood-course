{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca4bd0f-d9bd-41f1-84d9-2218b3f97bd5",
   "metadata": {},
   "source": [
    "# Comparing MAGs to public catalogues in MGnify, programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bedd9-8fab-4edd-8804-32cdad3ec8e5",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa889078-d05e-4cde-b54e-d9b3c66a0292",
   "metadata": {},
   "source": [
    "[pandas](https://pandas.pydata.org/docs/reference/index.html#api) is a data analysis library with a huge list of features. It is very good at holding and manipulating table data. It is almost always short-handed to `pd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3464561-e964-4a09-b6e0-ff1a4216d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d478f2-3f4c-4001-992f-d7dcec7a268b",
   "metadata": {},
   "source": [
    "`pathlib` is part of the Python standard library. We use it to find files and directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2b795-a105-4e9e-8787-555a5279073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8a928-1ba4-402c-a8c9-b887b0d161b7",
   "metadata": {},
   "source": [
    "`time` is part of the Python standard library. We will use it to wait for results from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6008eda-fb8d-4a34-82f1-6a5c14f35ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261bec4e-b3cb-462e-b32a-690630abd715",
   "metadata": {},
   "source": [
    "`tarfile` is part of the Python standard library. We will use it to extract compressed files from a `.tar.gz` file that the API gives us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fae654-b199-45c9-81c2-421a0eccf159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f95449-28fd-47a2-846b-cae8bacffd26",
   "metadata": {},
   "source": [
    "We need to compute a \"sketch\" for each Genome, using Sourmash. On the website this happens in your browser. To use the API, we do it using the [sourmash](https://sourmash.readthedocs.io/en/latest/) package. We will also use [Biopython’s SeqIO](https://biopython.org/wiki/SeqRecord) package to read the FASTA files in Python code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443ea77-f2a4-4deb-8899-cd60f9597bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sourmash\n",
    "from Bio import SeqIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbcb6c0-3eb6-4cb0-a2cf-e8e65c9004dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "holofood_mags_folder = Path('../data/salmon_mags/')\n",
    "\n",
    "holofood_mag_files = list(holofood_mags_folder.glob('*.fa'))\n",
    "holofood_mag_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd163cb-198e-46ff-8b18-5b843ce0220d",
   "metadata": {},
   "source": [
    "### Calculate sourmash \"sketches\" to search against the MGnify catalogue\n",
    "We’ll compute a sourmash sketch for each MAG. \n",
    "\n",
    "A sketch goes into a signature, that we will use for searching. \n",
    "\n",
    "The signature is a sort of collection of hashes that are well suited for calculating the *containment* of your MAGs within the catalogue's MAGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15c429-0308-43a8-afa5-fdf2fbfde033",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mag_file in holofood_mag_files:\n",
    "    # the sourmash parameters are chosen to match those used within MGnify\n",
    "    sketch = sourmash.MinHash(n=0, ksize=31, scaled=1000)\n",
    "    \n",
    "    # a fasta file may have multiple records in it. add them all to the sourmash signature.\n",
    "    for index, record in enumerate(SeqIO.parse(mag_file, 'fasta')):\n",
    "        sketch.add_sequence(str(record.seq))\n",
    "\n",
    "    # save the sourmash sketch as a \"signature\" file\n",
    "    sig = sourmash.SourmashSignature(sketch, name=record.name or mag_file.stem)\n",
    "    with open(mag_file.stem + '.sig', 'wt') as fp:\n",
    "        sourmash.save_signatures([sig], fp)\n",
    "\n",
    "# check what signature files we've created.\n",
    "# using ! in Jupyter lets you run a shell command. It is handy for quick things like pwd and ls.\n",
    "!ls *.sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a61bcc-05cc-44dd-a00b-8526c42273e8",
   "metadata": {},
   "source": [
    "### Submit a search job to the MGnify API\n",
    "We’ll call the MGnify API with all of our sketches.\n",
    "There is an endpoint for this (the same one used by the website).\n",
    "\n",
    "In this case, we need to **send** data to the API (not just fetch it). This is called \"POST\"ing data in the API world. \n",
    "\n",
    "This part of the API is quite specialized and so is not a formal JSON:API, so we use the more flexible [requests](https://docs.python-requests.org/en/master/) Python package to communicate with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276c4d4-bc1e-4159-bbf8-f8e64247934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da6383-fdfe-43a4-a394-38db7f68fd1a",
   "metadata": {},
   "source": [
    "We're going to compare the MAGs against the human gut catalogue. This might seem an odd choice, but the UHGG catalogue is by far the most comprehensive catalogue of MAGs in any biome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83b655-321d-42f0-b073-f8a80a7f019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https://www.ebi.ac.uk/metagenomics/api/v1/genomes-search/gather'\n",
    "catalogue_id = 'human-gut-v2-0'  # You could change this to any other catalogue ID from the MGnify website, if you use this in the future.\n",
    "\n",
    "# Create a list of file uploads, and attach them to the API request\n",
    "signatures = [open(mag.stem + '.sig', 'rb') for mag in holofood_mag_files]\n",
    "sketch_uploads = [('file_uploaded', signature) for signature in signatures]\n",
    "\n",
    "# Send the API request - it specifies which catalogue to search against and attaches all of the signature files.\n",
    "submitted_job = requests.post(endpoint, data={'mag_catalog': catalogue_id}, files=sketch_uploads).json()\n",
    "\n",
    "map(lambda fp: fp.close(), signatures)  # tidy up open file pointers\n",
    "\n",
    "print(submitted_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d47f0-6183-49a7-8b52-d2dd5f9deada",
   "metadata": {},
   "source": [
    "### Wait for our results to be ready\n",
    "As you can see in the printed `submitted_job` above, a `status_URL` was returned in the response from submitting the job via the API.\n",
    "Since the job will be in a queue, we must poll this `status_URL` to wait for our job to be completed.\n",
    "We’ll check every 2 seconds until ALL of the jobs are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13697b49-6cd4-4734-b379-97f7f1cd505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_done = False\n",
    "while not job_done:\n",
    "    print('Checking status...')\n",
    "    status = requests.get(submitted_job['data']['status_URL'])\n",
    "    # the status_URL is just another API endpoint that's unique for our search job\n",
    "    \n",
    "    queries_done = {sig['job_id']: sig['status'] for sig in status.json()['data']['signatures']}\n",
    "    job_done = all(map(lambda q: q == 'SUCCESS', queries_done.values()))\n",
    "    if not job_done:\n",
    "        print('Still waiting for jobs to complete. Current status of jobs')\n",
    "        print(queries_done)\n",
    "        print('Will check again in 2 seconds')\n",
    "        time.sleep(2)\n",
    "\n",
    "print('All finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09e957-1862-49e2-bc71-7adf0c4749b1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    If you happen to get an error at this point, just run the cell again. If lots of people are using the API at the same time it can sometimes struggle.\n",
    "</div>\n",
    "\n",
    "### See if we got any matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0187239-13d9-4fed-82f9-1705103a81dd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Coding challenge!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fcbd67-1b82-496d-ae1b-4764ae87271e",
   "metadata": {},
   "source": [
    "`status` is a JSON object. You can use the `status.json()` method to read the JSON into a Python `dict`.\n",
    "\n",
    "It'll look something like this:\n",
    "```json\n",
    "{'data': {'group_id': '...',\n",
    "  'signatures': [{\n",
    "    'status': 'SUCCESS',\n",
    "    'filename': '...',\n",
    "    'result': {\n",
    "        'status': 'NO_RESULTS',\n",
    "        'catalog': 'human-gut-v2-0',\n",
    "        'query_filename': '...'\n",
    "    }\n",
    "   },\n",
    "   {'job_id': '...',\n",
    "    'status': 'SUCCESS',\n",
    "    'filename': 'ERR4918all_bin.2.sig',\n",
    "    'result': {'overlap': '0.9 Mbp',\n",
    "     'p_query': '77.8%',\n",
    "     'p_match': '55.2%',\n",
    "     'match': 'MGYG000000001',\n",
    "     'catalog': 'human-gut-v2-0',\n",
    "     'query_filename': '...'},\n",
    "   }]\n",
    "}\n",
    "```\n",
    "\n",
    "I.e., `status.json()` contains a list of results in `['data']['signatures']`.\n",
    "Each object in that list has a `['signatures']` key with a value that is another dictionary.\n",
    "\n",
    "Write code to find any objects values in `data.signatures` that have a `result.match` entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159842e4-3d56-4af6-9073-eb9c2704d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c411c-e6c8-48a4-bc71-4ea26b7ea3b8",
   "metadata": {},
   "source": [
    "##### Solution\n",
    "Unhide the following cell for a solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad66008-f30a-4a1f-9889-2ebe1ae762bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matches = [sig for sig in status.json()['data']['signatures'] if 'match' in sig['result']]\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5947f-2062-4c9c-ac13-716adf0e69f5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Coding challenge!\n",
    "</div>\n",
    "\n",
    "Lets use the MGnify API to find out more about the matched MAGs.\n",
    "\n",
    "Complete this code to call the MGnify API endpoint `https://www.ebi.ac.uk/metagenomics/api/v1/genomes/MGYGxxxxxxxxx` for each `MGYGxx...` accession, using a GET request.\n",
    "The `MGYGxxx...` is in `matches[i]['result']['match']`.\n",
    "You'll get back JSON data. Save the `data.attributes` object (that's all the useful info about the MAG) to each match, as `matches[i]['mgnify_match_details']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c1d67-773e-4be9-872a-d82e0b71b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https...............\n",
    "\n",
    "for match in matches:\n",
    "    mgyg_in_public_catalogue = match['............\n",
    "                                     \n",
    "    mag_details_response = requests.get(f'.........................\n",
    "    match['mgnify_match_details'] = ....................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce9ab65-2a6f-46f6-8955-801774ddaa8b",
   "metadata": {},
   "source": [
    "##### Solution\n",
    "Unhide the cell below for the full solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2ac33-3ce4-4813-a607-8287d5215f2a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint = 'https://www.ebi.ac.uk/metagenomics/api/v1/genomes'\n",
    "\n",
    "for match in matches:\n",
    "    mgyg_in_public_catalogue = match['result']['match']\n",
    "    mag_details_response = requests.get(f'{endpoint}/{mgyg_in_public_catalogue}')\n",
    "    match['mgnify_match_details'] = mag_details_response.json()['data']['attributes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae59093-4fd5-4683-b289-ba188313c729",
   "metadata": {},
   "source": [
    "Put all of the results into a table (dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e935961-6219-4110-ae1e-629b5b2d032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_table = pd.json_normalize(matches)\n",
    "matches_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b02a66-4ef9-4d22-b00d-00cb90868061",
   "metadata": {},
   "source": [
    "#### In slightly more readable form..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14bf51a-cac1-4e28-9df8-8c8fd87dc2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_table[['filename', 'result.match', 'mgnify_match_details.taxon-lineage', 'result.p_query']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6b6bf-3fcc-4a31-951e-ba0fb920243d",
   "metadata": {},
   "source": [
    "### What taxonomic lineages do we have in the matches?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff570e-5d4a-4a1b-b470-f9db3d1295a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Coding challenge!\n",
    "</div>\n",
    "\n",
    "Use the Pandas `.unique()` method to list all of the taxonomic lineages from any of our matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b327704-0043-4065-8707-706754e88a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b2f65c8-c4a0-4c4c-9dcc-ef685709dcbd",
   "metadata": {},
   "source": [
    "##### Solution\n",
    "Unhide the cell below for a solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d4727-a22a-415b-927c-302f0532954b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matches_table['mgnify_match_details.taxon-lineage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d4eb0-1556-4b0a-9ea4-f20df5970c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holofood-course",
   "language": "python",
   "name": "holofood-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
